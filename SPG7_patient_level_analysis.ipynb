{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages (0.10.1)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in /Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from seaborn) (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from seaborn) (1.18.5)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from seaborn) (0.25.3)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from seaborn) (1.5.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from pandas>=0.22.0->seaborn) (2019.3)\n",
      "Requirement already satisfied: six in /Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.2->seaborn) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/dilution/.pyenv/versions/3.7.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cyvcf2 import VCF\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "# prospax file collection\n",
    "df_spg7 = pd.read_csv(\"SPG7/SPG7_all_partners.tsv\", sep=\"\\t\")\n",
    "# variant list formated\n",
    "df_spg7_extended = pd.read_csv(\"SPG7/SPG7.prospax.extended.annotated.tsv\", sep=\"\\t\")\n",
    "# spg7_vcf_clinvar = VCF(\"ext_data/clinvar/05_2021/SPG7.clinvar.annotated.vcf\")\n",
    "df_spg7_clinvar = pd.read_csv(\"SPG7/SPG7.clinvar.extended.annotated.tsv\", sep=\"\\t\")\n",
    "# gnomad spg7\n",
    "df_gnom_ad = pd.read_csv(\"SPG7/SPG7.gnomad.tsv\", sep=\"\\t\")\n",
    "# uniprot_spg7 \n",
    "uniprot_var = pd.read_csv(\"SPG7/SPG7_uniprot_annotated.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Analysis\n",
    "\n",
    "Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change df_sacs columns name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"submitter_id\",\n",
    "    \"local_case_id\",\n",
    "    \"local_family_id\",\n",
    "    \"prospax_case_id\",\n",
    "    \"ngs_database_id\",\n",
    "    \"main_phenotype\",\n",
    "    \"case_status\",\n",
    "    \"id\",\n",
    "    \"gene\",\n",
    "    \"chrom\",\n",
    "    \"pos\",\n",
    "    \"ref\",\n",
    "    \"alt\",\n",
    "    \"transcript_id\",\n",
    "    \"cdna\",\n",
    "    \"prot_change\",\n",
    "    \"genotype\",\n",
    "    \"compound_het_id_s\",\n",
    "    \"paxgene_availability\",\n",
    "    \"pbmc_availability\",\n",
    "    \"fibroblasts_availability\",\n",
    "    \"comments\",\n",
    "    \"Variant_based_id\",\n",
    "]\n",
    "\n",
    "df_spg7.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify mutation type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regroup_csq(x):\n",
    "    if x in [\"3_prime_UTR_variant\", \"5_prime_UTR_variant\"]:\n",
    "        return \"UTR\"\n",
    "    elif x in [\"inframe_insertion\", \"inframe_deletion\", 'inframe_deletion&splice_region_variant']:\n",
    "        return \"Inframe_Indel\"\n",
    "    elif x in [\"intron_variant\" ]:\n",
    "        return \"Intron\"\n",
    "    elif x in [\"missense_variant\", \"missense_variant&splice_region_variant\"]:\n",
    "        return \"Missense\"\n",
    "    elif x in ['splice_region_variant&intron_variant',\n",
    "              'splice_region_variant&synonymous_variant', 'splice_region_variant&5_prime_UTR_variant']:\n",
    "        return \"Splice_region\"\n",
    "    elif x in [\"splice_acceptor_variant\", \"splice_donor_variant\", \"splice_donor_variant&intron_variant\", 'splice_donor_variant&coding_sequence_variant&intron_variant',\n",
    "              'splice_acceptor_variant&coding_sequence_variant&intron_variant', \n",
    "              'splice_acceptor_variant&coding_sequence_variant']:\n",
    "        return \"Canonical_splice\"\n",
    "    elif x in [\"start_lost\", \"stop_lost\", \"stop_gained\", \"stop_gained&splice_region_variant\", 'stop_gained&inframe_insertion',\n",
    "               'stop_gained&protein_altering_variant']:\n",
    "        return \"Nonsense\"\n",
    "    elif x in ['protein_altering_variant', \"frameshift_variant\", \"frameshift_variant&stop_lost\",\n",
    "               \"stop_gained&frameshift_variant\", 'splice_donor_variant&splice_acceptor_variant&frameshift_variant&stop_lost&intron_variant',\n",
    "               'frameshift_variant&splice_region_variant', 'frameshift_variant&splice_region_variant']:\n",
    "        return \"Frameshift\"\n",
    "    elif x in [\"synonymous_variant\"]:\n",
    "        return \"Synonymous\"\n",
    "    elif x in ['upstream_gene_variant']:\n",
    "        return \"Intergene\"\n",
    "    \n",
    "    \n",
    "df_spg7_clinvar[\"csq_minimal\"] = df_spg7_clinvar[\"csq\"].apply(lambda x: regroup_csq(x))\n",
    "df_spg7_extended[\"csq_minimal\"] = df_spg7_extended[\"csq\"].apply(lambda x: regroup_csq(x))\n",
    "df_gnom_ad[\"csq_minimal\"] = df_gnom_ad[\"mutation_type\"].apply(lambda x: regroup_csq(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADD variant_based_id column to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spg7_clinvar[\"Variant_based_id\"] = df_spg7_clinvar[[\"chrom\", \"pos\", \"ref\", \"alt\"]].apply(lambda x: \"-\".join(x.values.astype(str)), axis=1)\n",
    "df_spg7_extended[\"Variant_based_id\"] = df_spg7_extended[[\"chrom\", \"pos\", \"ref\", \"alt\"]].apply(lambda x: \"-\".join(x.values.astype(str)), axis=1)\n",
    "df_gnom_ad.rename(columns={\"variant_id\":\"Variant_based_id\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify case status \n",
    "unsure and not solved could be re-grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get variant set(ids) from different case status\n",
    "solved_ids = set(df_spg7[df_spg7['case_status']==\"solved SPG7\"][\"Variant_based_id\"])\n",
    "unsure_notsolved_ids = set(df_spg7[df_spg7['case_status'].isin([\"not solved\", \"unsure\"])][\"Variant_based_id\"])\n",
    "solved_other_ids = set(df_spg7[df_spg7['case_status']==\"solved other gene\"][\"Variant_based_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADD protein domain info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hgvs.parser\n",
    "import numpy as np\n",
    "\n",
    "def clean_hgvsp(x):\n",
    "    if x==\"n/a\" or x==\"-1\":\n",
    "        return \"n/a\"\n",
    "    else:\n",
    "        return x.replace(\"%3D\", \"=\")\n",
    "        \n",
    "def short_prot_desc(x):\n",
    "    if x==\"n/a\":\n",
    "        return \"n/a\"\n",
    "    else:\n",
    "        return x.split(\":\")[1]\n",
    "\n",
    "def get_prot_pos(x, hp):\n",
    "    if x==\"n/a\":\n",
    "        return -1\n",
    "    else:\n",
    "        p = hp.parse_hgvs_variant(x)\n",
    "        return p.posedit.pos.start.base\n",
    "    \n",
    "\n",
    "    \n",
    "hp = hgvs.parser.Parser()\n",
    "\n",
    "# list spg7 prospax variant\n",
    "df_spg7_extended[\"hgvsp\"].fillna(\"n/a\", inplace=True)\n",
    "df_spg7_extended[\"hgvsp_clean\"] = df_spg7_extended[\"hgvsp\"].apply(lambda x: clean_hgvsp(x))\n",
    "df_spg7_extended[\"hgvsp_short\"] = df_spg7_extended[\"hgvsp_clean\"].apply(lambda x: short_prot_desc(x))\n",
    "df_spg7_extended[\"protein_pos\"] = df_spg7_extended[\"hgvsp_clean\"].apply(lambda x: get_prot_pos(x, hp))\n",
    "\n",
    "# list clinvar variant\n",
    "df_spg7_clinvar[\"hgvsp\"].fillna(\"n/a\", inplace=True)\n",
    "df_spg7_clinvar[\"hgvsp_clean\"] = df_spg7_clinvar[\"hgvsp\"].apply(lambda x: clean_hgvsp(x))\n",
    "df_spg7_clinvar[\"hgvsp_short\"] = df_spg7_clinvar[\"hgvsp_clean\"].apply(lambda x: short_prot_desc(x))\n",
    "df_spg7_clinvar[\"protein_pos\"] = df_spg7_clinvar[\"hgvsp_clean\"].apply(lambda x: get_prot_pos(x, hp))\n",
    "\n",
    "# list gnomad variant\n",
    "df_gnom_ad[\"hgvsp\"].fillna(\"n/a\", inplace=True)\n",
    "df_gnom_ad[\"hgvsp_clean\"] = df_gnom_ad[\"hgvsp\"].apply(lambda x: clean_hgvsp(x))\n",
    "df_gnom_ad[\"hgvsp_short\"] = df_gnom_ad[\"hgvsp_clean\"].apply(lambda x: short_prot_desc(x))\n",
    "df_gnom_ad[\"protein_pos\"] = df_gnom_ad[\"hgvsp_clean\"].apply(lambda x: get_prot_pos(x, hp))\n",
    "\n",
    "\n",
    "# list gnomad variant\n",
    "uniprot_var[\"hgvsp\"].fillna(\"n/a\", inplace=True)\n",
    "uniprot_var[\"hgvsp_clean\"] = uniprot_var[\"hgvsp\"].apply(lambda x: clean_hgvsp(x))\n",
    "uniprot_var[\"hgvsp_short\"] = uniprot_var[\"hgvsp_clean\"].apply(lambda x: short_prot_desc(x))\n",
    "uniprot_var[\"protein_pos\"] = uniprot_var[\"hgvsp_clean\"].apply(lambda x: get_prot_pos(x, hp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spg7_domain = pd.read_csv(\"SPG7/spg7.bed\", sep=\" \", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "# map of regions\n",
    "spg7_prot = {\n",
    "    \"0_MTS\": (1, 59),\n",
    "    \"1_inter\": (60, 142),\n",
    "    \"2_FtsH\": (143, 144),\n",
    "    \"3_TM1\": (145, 166),\n",
    "    \"4_FtsH\": (167, 237),\n",
    "    \"5_inter\": (238, 249),\n",
    "    \"6_TM2\": (250, 272),\n",
    "    \"7_inter\": (273, 305),\n",
    "    \"8_AAA+_ATPase\": (306, 481),\n",
    "    \"9_inter\": (482, 507),\n",
    "    \"10_AAA+_lid\": (508, 543),\n",
    "    \"11_M41_peptidase\": (544, 746),\n",
    "    \"12_inter\": (746, 796),\n",
    "    \n",
    "}\n",
    "\n",
    "# reduce to categories\n",
    "ref = {\n",
    "    \"0_inter\": (0, [1, 5, 7, 9, 12]),\n",
    "    \"1_MTS\": (1, [0]),\n",
    "    \"2_FtsH\": (2, [2, 4]),\n",
    "    \"3_TM\": (3, [3, 6]),\n",
    "    \"4_AAA+_ATPase\": (4, [8]),\n",
    "    \"5_AAA+_lid\": (5, [10]),\n",
    "    \"6_M41_peptidase\": (6, [11]),\n",
    "}\n",
    "\n",
    "def get_domain_name(x, map_dom):\n",
    "    \n",
    "    if x==-1:\n",
    "        return -1\n",
    "    else:\n",
    "        intervals = sorted([v[1] for i, v in map_dom.items()])\n",
    "        intervals_name = [i for i in map_dom]\n",
    "        domain = bisect.bisect_left(intervals, x)\n",
    "        domain_name = intervals_name[domain]\n",
    "        return domain_name\n",
    "\n",
    "def get_domain_cat(x, map_dom, ref):\n",
    "    if x==-1:\n",
    "        return -1\n",
    "    else:\n",
    "        intervals = sorted([v[1] for i, v in map_dom.items()])\n",
    "        # intervals_name = [i for i in map_dom]\n",
    "        domain = bisect.bisect_left(intervals, x)\n",
    "        for i, v in ref.items():\n",
    "            if domain in v[1]:\n",
    "                return v[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to df_var\n",
    "df_spg7_extended[\"domain_name\"] = df_spg7_extended[\"protein_pos\"].apply(lambda x: get_domain_name(x, spg7_prot))\n",
    "df_spg7_extended[\"cat_domain\"] = df_spg7_extended[\"protein_pos\"].apply(lambda x: get_domain_cat(x, spg7_prot, ref))\n",
    "\n",
    "# clinvar\n",
    "df_spg7_clinvar[\"domain_name\"] = df_spg7_clinvar[\"protein_pos\"].apply(lambda x: get_domain_name(x, spg7_prot))\n",
    "df_spg7_clinvar[\"cat_domain\"] = df_spg7_clinvar[\"protein_pos\"].apply(lambda x: get_domain_cat(x, spg7_prot, ref))\n",
    "\n",
    "\n",
    "# gnomad\n",
    "df_gnom_ad[\"domain_name\"] = df_gnom_ad[\"protein_pos\"].apply(lambda x: get_domain_name(x, spg7_prot))\n",
    "df_gnom_ad[\"cat_domain\"] = df_gnom_ad[\"protein_pos\"].apply(lambda x: get_domain_cat(x, spg7_prot, ref))\n",
    "\n",
    "# uniprot\n",
    "uniprot_var[\"domain_name\"] = uniprot_var[\"protein_pos\"].apply(lambda x: get_domain_name(x, spg7_prot))\n",
    "uniprot_var[\"cat_domain\"] = uniprot_var[\"protein_pos\"].apply(lambda x: get_domain_cat(x, spg7_prot, ref))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparatory steps\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Annotate variants uniformely --> (done with VEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Identify and flag likely pathogenic variants\n",
    "- All rare truncating variants (nonsense, frameshift, canonical splice)\n",
    "- All ClinVar likely pathogenic / pathogenic variants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_lp_p(x, list_v_id):\n",
    "    if x in list_v_id:\n",
    "        return \"y\"\n",
    "    else:\n",
    "        return \"n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get truncating mutation \n",
    "truncating_type = ['Nonsense', 'Frameshift', 'Canonical_splice']\n",
    "list_v_id_truncating = df_spg7_extended[df_spg7_extended[\"csq_minimal\"].isin(truncating_type)][\"Variant_based_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get likely pathogenic and pathogenic from clinvar and uniprot\n",
    "# inner merge clinvar prospax\n",
    "# assertion considered are: \n",
    "# 'reviewed_by_expert_panel',\n",
    "# 'criteria_provided,_single_submitter',\n",
    "# 'criteria_provided,_multiple_submitters,_no_conflicts'\n",
    "inner_merge_clinvar_prospax = pd.merge(df_spg7_clinvar[[\"Variant_based_id\", 'clinsig', 'clinsigconflict','clinsigincl']], df_spg7_extended, how=\"inner\", on=[\"Variant_based_id\"])\n",
    "lp_p_labels = ['Likely_pathogenic', 'Pathogenic/Likely_pathogenic', 'Pathogenic']\n",
    "lp_p_clinvar = inner_merge_clinvar_prospax[inner_merge_clinvar_prospax[\"clinsig\"].isin(lp_p_labels)][\"Variant_based_id\"].unique()\n",
    "\n",
    "# inner merge uniprot prospax \n",
    "# pathogenic are labeled as 2 in clinsig col\n",
    "inner_merge_uniprot_prospax = pd.merge(uniprot_var[[\"Variant_based_id\", 'clinsig']], df_spg7_extended, how=\"inner\", on=[\"Variant_based_id\"])\n",
    "lp_p_uniprot = inner_merge_uniprot_prospax[inner_merge_uniprot_prospax[\"clinsig\"]==3][\"Variant_based_id\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add gross indels to list of lp_p variants\n",
    "gross_indels = list(df_spg7[df_spg7[\"ref\"].isin([\"dup\", \"del\"])][\"Variant_based_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 16-89613145-C-T - p.Ala510Val \n",
    "manual_addition = [\"16-89613145-C-T\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge lists lp/p uniprot / clinvar / truncating variants\n",
    "# and flag them in variant collection\n",
    "final_lp_p_id = list(set(list(lp_p_clinvar) + list(lp_p_uniprot) + list(list_v_id_truncating) + gross_indels + manual_addition))\n",
    "df_spg7_extended[\"is_lp_p\"] = df_spg7_extended[\"Variant_based_id\"].apply(lambda x: flag_lp_p(x, final_lp_p_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variant being reported as LP/P in clinvar/uniprot: 72\n"
     ]
    }
   ],
   "source": [
    "# a\n",
    "print(\"Number of variant being reported as LP/P in clinvar/uniprot: {}\".format(len(final_lp_p_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Filter remaining variants uniformely\n",
    "- Keep all likely pathogenic variants\n",
    "- Filter criteria for remaining variants: \n",
    "    - MAF < 0.5%\n",
    "    - highly conserved (missense only: PhasCons ≥ 0.7, GERP ≥ 2) (to be discussed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_maf(df, threshold=0.005):\n",
    "    df_filt = df[(df['thKg']<=threshold) &\n",
    "                 (df['gnomad_ex']<=threshold) &\n",
    "                 (df['gnomad_gn']<=threshold)\n",
    "                ]\n",
    "    return df_filt\n",
    "\n",
    "def filter_conservation(df, phastcons_min=0.7, gerp_min=2):\n",
    "    df_filt = df[((df['gerp_rs']>=gerp_min) | (df['gerp_rs'].isnull())) &\n",
    "                 ((df['phastcons']>=phastcons_min) | (df['phastcons'].isnull())) \n",
    "                ]\n",
    "    return df_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244, 56)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of variants not lp/p\n",
    "df_not_lp_p = df_spg7_extended[df_spg7_extended[\"is_lp_p\"]==\"n\"]\n",
    "df_not_lp_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the non-LP/P variant from preparatory steps\n",
    "# filter on MAF<=0.5%\n",
    "# filter on conservation pref (gerp, phastcons)\n",
    "df_freq1 = filter_maf(df_not_lp_p)\n",
    "df_freq_conserver_filtered = filter_conservation(df_freq1)\n",
    "final_conserved_variant_id = list(df_freq_conserver_filtered[\"Variant_based_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag variants if lp/p - conserved - none\n",
    "def flag_conserved(x, list_lp_p, list_rare_conserved):\n",
    "    if x in list_rare_conserved:\n",
    "        return \"rare_conserved\"\n",
    "    elif x in list_lp_p:\n",
    "        return \"lp_p\"\n",
    "    else:\n",
    "        return \"not_conserved\"\n",
    "    \n",
    "    \n",
    "df_spg7_extended[\"is_conserved\"] = df_spg7_extended[\"Variant_based_id\"].apply(lambda x: flag_conserved(x, final_lp_p_id, final_conserved_variant_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 56)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq_conserver_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A - Tier 1: Cases carrying 2 likely pathogenic variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Identify cases carrying two (likely) pathogenic variants\n",
    "- flag cases as “solved”\n",
    "- filter out all variants in solved cases\n",
    "- collect phenotypic information, perform segregation analysis, consider functional assays (e.g. as positive controls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unique patient (submitter-localsubjectid)\n",
    "df_lp_p = df_spg7[df_spg7[\"Variant_based_id\"].isin(final_lp_p_id)]\n",
    "\n",
    "unique_case_list = set([(row['submitter_id'],row['local_case_id']) \n",
    "                    for idx, row in df_lp_p.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_cases(cases, df):\n",
    "    for case in cases:\n",
    "        yield((case, df[(df['local_case_id']==case[1]) & \\\n",
    "                 (df['submitter_id']==case[0])]))\n",
    "\n",
    "# check if patient has one gross dup/del        \n",
    "def is_large_dup_del(df):\n",
    "    if \"dup\" in df['ref'].values:\n",
    "        return True\n",
    "    elif \"del\" in df['ref'].values:\n",
    "        return True\n",
    "    else:\n",
    "        False\n",
    "        \n",
    "# check if patient has 2 lp/p variants       \n",
    "def is_2_lp_p(df, list_lp_p):\n",
    "    if df[df[\"Variant_based_id\"].isin(list_lp_p)].shape[0]>=2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# check if patient has 1 lp/p variant + one gross dup/del\n",
    "def is_lpp_del_dup(df, list_lp_p):\n",
    "    if df[df[\"Variant_based_id\"].isin(list_lp_p)].shape[0]>1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# check if patient has Hom lp/p variant\n",
    "def is_lp_p_hom(df, list_lp_p):\n",
    "    if df[(df[\"Variant_based_id\"].isin(list_lp_p)) &\n",
    "       (df[\"genotype\"]==\"Hom\")].empty:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def tier1_screen_case(df, list_lp_p):\n",
    "    # if one variant from lp/p list only variant hom\n",
    "    if df.shape[0]==1:\n",
    "        return True\n",
    "    # if more than one variant in case\n",
    "    elif df.shape[0]>1:\n",
    "        # if on variant is a gross del/dup\n",
    "        if is_large_dup_del(df):\n",
    "            # if one gross dup/del + one lp/p variant\n",
    "            if is_lpp_del_dup(df, list_lp_p):\n",
    "                return True\n",
    "            else:\n",
    "                # if just one gross dup/del\n",
    "                return False\n",
    "        # if 2 lp/p het / caveats ID27288 + 357-987-169\n",
    "        elif is_2_lp_p(df, list_lp_p):\n",
    "            return True\n",
    "        # if one HOM lp/p variants and other non het/HOM non-lp/p variants\n",
    "        elif is_lp_p_hom(df, list_lp_p):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_dup_del_lp = df_spg7[df_spg7[\"local_case_id\"]==\"FSP-SAL-DEL-1469-001\"]    \n",
    "test_2_lp_p = df_spg7[df_spg7[\"local_case_id\"]==\"AAD-SAL-TRI-785-009\"]  \n",
    "test_not_2_lp = df_spg7[df_spg7[\"local_case_id\"]==\"ALS2039\"]\n",
    "test_hom_many = df_spg7[df_spg7[\"local_case_id\"]==\"Family-HSP-139\"]\n",
    "test_gross_hom = df_spg7[df_spg7[\"local_case_id\"]==\"ID34038\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true\n",
    "tier1_screen_case(test_dup_del_lp, final_lp_p_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true\n",
    "tier1_screen_case(test_2_lp_p, final_lp_p_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false\n",
    "tier1_screen_case(test_not_2_lp, final_lp_p_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true\n",
    "tier1_screen_case(test_hom_many, final_lp_p_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true\n",
    "tier1_screen_case(test_gross_hom, final_lp_p_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on all cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# collect case local id having 2 lp/p variants or 1 lp/p variant + gross del/dup\n",
    "solved_cases = []\n",
    "for case in stream_cases(unique_case_list, df_spg7):\n",
    "    patient = case[0]\n",
    "    df = case[1]\n",
    "    if tier1_screen_case(df, final_lp_p_id):\n",
    "        solved_cases.append(patient)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract cases from prospax collection\n",
    "# flag them in df_spg7\n",
    "def is_solved(x, solved_id):\n",
    "    if x in solved_id:\n",
    "        return \"y\"\n",
    "    else:\n",
    "        return \"n\"\n",
    "solved_local_ids = {case[1] for case in solved_cases}\n",
    "df_spg7[\"tier1_is_solved\"] = df_spg7[\"local_case_id\"].apply(lambda x: is_solved(x, solved_local_ids))\n",
    "df_solved = df_spg7[df_spg7[\"local_case_id\"].isin(solved_local_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique cases being tier1: 201\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique cases being tier1: {}\".format(df_solved[\"local_case_id\"].unique().shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cases being tier 1\n",
    "df_solved.to_csv(\"SPG7/tier1/tier1_solved_case.tsv\", sep=\"\\t\", index=False)\n",
    "df_solved.to_excel(\"SPG7/tier1/tier1_solved_case.xlsx\", index=False, freeze_panes=(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract variant list being lp/p and Tier1\n",
    "tiers1_variant_id = df_solved[df_solved[\"Variant_based_id\"].isin(final_lp_p_id)][\"Variant_based_id\"].unique()\n",
    "tiers1_variants = df_spg7_extended[df_spg7_extended[\"Variant_based_id\"].isin(tiers1_variant_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving tier1: lp-p variants \n",
    "tiers1_variants.to_csv(\"SPG7/tier1/tiers_solved_variants.tsv\", sep=\"\\t\", index=False)\n",
    "tiers1_variants.to_excel(\"SPG7/tier1/tiers_solved_variants.xlsx\", index=False, freeze_panes=(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_solved[\"Variant_based_id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B - Tier 2: Cases carrying 1 likely pathogenic variants in combination with a VUS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 -  Identify cases carrying 1 likely pathogenic variant in combination with at least 1 additional variant\n",
    "- depending on the number of remaining cases, proceed to functional follow up or consider additional filtering steps\n",
    "- criteria supporting pathogenicity: \n",
    "    - phenotype matches SACS/SPG7\n",
    "    - variants segregate in the family\n",
    "    - highly conserved, predicted deleterious (to be discussed)\n",
    "    - missense variant is located in a functional domain\n",
    "    - variant has functional effect (splicing, downregulation of protein, downstream functional effect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unique patient (submitter-localsubjectid)\n",
    "df_tier2_prep = df_spg7[df_spg7[\"tier1_is_solved\"]==\"n\"]\n",
    "# print(df_tier2_prep.shape)\n",
    "df_tier2_prep = df_tier2_prep[df_tier2_prep[\"Variant_based_id\"].isin(final_lp_p_id)]\n",
    "# print(df_tier2_prep.shape)\n",
    "tier2_unique_case_list = set([(row['submitter_id'],row['local_case_id']) \n",
    "                    for idx, row in df_tier2_prep.iterrows()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** remember to use non-lp/p conserved&rare variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_conserved_variants = df_freq_conserver_filtered[\"Variant_based_id\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** create list of benign-likelybenign variants to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_clinvar = list(df_spg7_clinvar[df_spg7_clinvar[\"clinsig\"].isin(['Likely_benign', 'Benign', 'Benign/Likely_benign'])][\"Variant_based_id\"].unique())\n",
    "\n",
    "benign_uniprot = list(uniprot_var[uniprot_var[\"clinsig\"]==1][\"Variant_based_id\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list_benign = list(set(benign_clinvar + benign_uniprot))\n",
    "# add flag in main variant collection - is_variant_benign reported\n",
    "def is_benign_uniprot_clinvar(x, list_benign):\n",
    "    if x in list_benign:\n",
    "        return \"y\"\n",
    "    else:\n",
    "        return \"n\"\n",
    "    \n",
    "df_spg7_extended[\"has_benign_report\"] = df_spg7_extended[\"Variant_based_id\"].apply(lambda x: is_benign_uniprot_clinvar(x, final_list_benign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def stream_cases(cases, df):\n",
    "    for case in cases:\n",
    "        yield((case, df[(df['local_case_id']==case[1]) & \\\n",
    "                 (df['submitter_id']==case[0])]))\n",
    "        \n",
    "def get_lp_p_variant(df, list_lp_p):\n",
    "    list_df_lp_p = list(df[df[\"Variant_based_id\"].isin(list_lp_p)][\"Variant_based_id\"])\n",
    "    return list_df_lp_p\n",
    "\n",
    "def get_rare_conserved_variant(df, list_conserved_rare):\n",
    "    list_df_conserverd_rare = list(df[df[\"Variant_based_id\"].isin(list_conserved_rare)][\"Variant_based_id\"])\n",
    "    return list_df_conserverd_rare\n",
    "\n",
    "def get_benign_variant(df, list_benign):\n",
    "    list_df_benign = list(df[df[\"Variant_based_id\"].isin(list_benign)][\"Variant_based_id\"])\n",
    "    return list_df_benign\n",
    "\n",
    "def get_all_var_not_lpp(df, v_lp_p):\n",
    "    v_not_lpp = [v for v in df[\"Variant_based_id\"].unique() if v not in v_lp_p]\n",
    "    return v_not_lpp\n",
    "\n",
    "def get_hyp_vus(v_not_lpp, v_benign, v_rare_conserved):\n",
    "    hyp_vus = [v for v in v_not_lpp if v not in v_benign and v in v_rare_conserved]\n",
    "    return hyp_vus\n",
    "\n",
    "def is_tier2(df, df_length, v_lp_p, v_benign, v_rare_conserved):\n",
    "    if df_length==2:\n",
    "        if len(v_lp_p)==1 and len(v_benign)==0 and len(v_rare_conserved)==1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        not_lpp_v = get_all_var_not_lpp(df, v_lp_p)\n",
    "        hyp_vus = get_hyp_vus(not_lpp_v, v_benign, v_rare_conserved)\n",
    "        if hyp_vus:\n",
    "            return True\n",
    "        else: \n",
    "            return False\n",
    "        \n",
    "def tier2_screen_case(df, list_lp_p, list_conserved_rare, list_benign):\n",
    "    if df.shape[0]==1:\n",
    "        print(\"problem 1 variant only\", list(df[\"Variant_based_id\"]))\n",
    "    else:\n",
    "        v_lp_p = get_lp_p_variant(df, list_lp_p)\n",
    "        # print(\"lp_p\", len(v_lp_p))\n",
    "        v_benign = get_benign_variant(df, list_benign)\n",
    "        # print(\"benign\", len(v_benign))\n",
    "        v_rare_conserved = get_rare_conserved_variant(df, list_conserved_rare)\n",
    "        # print(\"conserved_rare\", len(v_rare_conserved))\n",
    "        df_length = df.shape[0]\n",
    "        \n",
    "        return is_tier2(df, df_length, v_lp_p, v_benign, v_rare_conserved)\n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('P6 - Istanbul', 'MYO19') not tier2\n",
      "('P1 - Tübingen', 'ID28189') not tier2\n",
      "('P4 - Pisa', '2424A') not tier2\n",
      "('P6 - Istanbul', 'FTD56') not tier2\n"
     ]
    }
   ],
   "source": [
    "tier2_cases = []\n",
    "tier2_cases_rejected = []\n",
    "for case in stream_cases(tier2_unique_case_list, df_spg7):\n",
    "    patient = case[0]\n",
    "    df = case[1]\n",
    "    if tier2_screen_case(df, final_lp_p_id, final_conserved_variant_id, final_list_benign):\n",
    "        tier2_cases.append(patient)\n",
    "    else:\n",
    "        tier2_cases_rejected.append(patient)\n",
    "        print(patient, \"not tier2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# extract cases from prospax collection\n",
    "# flag them in df_spg7\n",
    "def flag_tier2(x, tier2_id, tier2_cases_rejected):\n",
    "    if x in tier2_id:\n",
    "        return \"y\"\n",
    "    elif x in tier2_cases_rejected:\n",
    "        return \"rejected_automatic_not_rare/conserved_or_benign_report\"\n",
    "    else:\n",
    "        return \"n\"\n",
    "\n",
    "def flag_tier2_variant_lvl(x, lp_p, rare_conserved, benign):\n",
    "    if x in lp_p:\n",
    "        return \"lp_p_variant\"\n",
    "    elif x in rare_conserved and x not in benign:\n",
    "        return \"rare_conserved_variant\"\n",
    "    elif x not in rare_conserved and x not in benign:\n",
    "        return \"NOT_rare_conserved_variant\"\n",
    "    elif x not in rare_conserved and x in benign:\n",
    "        return \"NOT_rare_conserved_variant_AND_benign_report\"\n",
    "    \n",
    "tier2_local_ids = {case[1] for case in tier2_cases}\n",
    "tier2_rejected_local_ids = {case[1] for case in tier2_cases_rejected}\n",
    "df_spg7[\"is_tier2\"] = df_spg7[\"local_case_id\"].apply(lambda x: flag_tier2(x, tier2_local_ids, tier2_rejected_local_ids))\n",
    "df_tier2 = df_spg7[df_spg7[\"local_case_id\"].isin(tier2_local_ids)]\n",
    "df_tier2[\"variant_level_status\"] = df_tier2[\"Variant_based_id\"].apply(lambda x: flag_tier2_variant_lvl(x, final_lp_p_id, final_conserved_variant_id, final_list_benign))\n",
    "df_tier2_rejected = df_spg7[df_spg7[\"local_case_id\"].isin(tier2_rejected_local_ids)]\n",
    "df_tier2_rejected[\"variant_level_status\"] = df_tier2_rejected[\"Variant_based_id\"].apply(lambda x: flag_tier2_variant_lvl(x, final_lp_p_id, final_conserved_variant_id, final_list_benign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# create column to flag questionable variants \n",
    "def flag_questionable(x):\n",
    "    if x == \"lp_p_variant\":\n",
    "        return 0\n",
    "    elif x == \"rare_conserved_variant\":\n",
    "        return 2\n",
    "    elif x in [\"NOT_rare_conserved_variant\", \"NOT_rare_conserved_variant_AND_benign_report\"]:\n",
    "        return 1\n",
    "    \n",
    "df_tier2[\"is_questionable\"] = df_tier2[\"variant_level_status\"].apply(lambda x: flag_questionable(x))\n",
    "df_tier2_rejected[\"is_questionable\"] = df_tier2_rejected[\"variant_level_status\"].apply(lambda x: flag_questionable(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tier2_variants = df_spg7_extended[df_spg7_extended[\"Variant_based_id\"].isin(df_tier2[\"Variant_based_id\"].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def flag_questionable_var(x):\n",
    "    if x == \"lp_p\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "df_tier2_variants[\"is_questionable_variant\"] = df_tier2_variants[\"is_conserved\"].apply(lambda x: flag_questionable_var(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tier2_variants.to_csv(\"SPG7/tier2/tiers2_cases_variants.tsv\", sep=\"\\t\", index=False)\n",
    "df_tier2_variants.to_excel(\"SPG7/tier2/tiers2_cases_variants.xlsx\", index=False, freeze_panes=(1,4))\n",
    "df_tier2.to_csv(\"SPG7/tier2/tier2_cases.tsv\", sep=\"\\t\", index=False)\n",
    "df_tier2.to_excel(\"SPG7/tier2/tier2_cases.xlsx\", index=False, freeze_panes=(1,4))\n",
    "df_tier2_rejected.to_csv(\"SPG7/tier2/tier2_rejected_cases.tsv\", sep=\"\\t\", index=False)\n",
    "df_tier2_rejected.to_excel(\"SPG7/tier2/tier2_rejected_cases.xlsx\", index=False, freeze_panes=(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_tier2[\"local_case_id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_p 1\n",
      "benign 2\n",
      "conserved_rare 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False - one lp-p + benign + not conserved\n",
    "test_one_lp_benign = df_spg7[df_spg7[\"local_case_id\"]==\"2424A\"]\n",
    "tier2_screen_case(test_one_lp_benign, final_lp_p_id, final_conserved_variant_id, final_list_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True\n",
    "test_true = df_spg7[df_spg7[\"local_case_id\"]==\"HSP10\"]\n",
    "tier2_screen_case(test_true, final_lp_p_id, final_conserved_variant_id, final_list_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lp_p 1\n",
      "benign 0\n",
      "conserved_rare 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False - one lp/p + one not conserved/rare variant\n",
    "test_false_not_conserved_rare = df_spg7[df_spg7[\"local_case_id\"]==\"FTD56\"]\n",
    "tier2_screen_case(test_false_not_conserved_rare, final_lp_p_id, final_conserved_variant_id, final_list_benign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C - Tier 3: Cases carrying 2 VUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Identify cases carrying 2 variants of unknown significance\n",
    "- apply standard filters\n",
    "- depending on the number of remaining cases, proceed to functional follow up or consider additional filtering steps\n",
    "- criteria supporting pathogenicity: \n",
    "    - phenotype matches SACS/SPG7\n",
    "    - variants segregate in the family\n",
    "    - missense variant is located in a functional domain\n",
    "    - variant has functional effect (splicing, downregulation of protein, downstream functional effect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases to investigate in the context of Tier3 analysis: 141\n"
     ]
    }
   ],
   "source": [
    "# get cases which are not included in tier1 and tier2\n",
    "df_tier3_prep = df_spg7[(df_spg7[\"tier1_is_solved\"]==\"n\") & (df_spg7[\"is_tier2\"]==\"n\")]\n",
    "\n",
    "print(\"Number of cases to investigate in the context of Tier3 analysis: {}\".format(len(df_tier3_prep[\"local_case_id\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cases to investigate\n",
    "tier3_unique_case_list = df_tier3_prep[\"local_case_id\"].unique()\n",
    "# get variants id tier3\n",
    "variants_tier3_unique_cases = df_tier3_prep[\"Variant_based_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variants to investigate in the context of Tier3 analysis: 213\n"
     ]
    }
   ],
   "source": [
    "# get variants from tier3_unique_case_list\n",
    "df_pre_tier3_variants = df_spg7_extended[df_spg7_extended[\"Variant_based_id\"].isin(variants_tier3_unique_cases)]\n",
    "\n",
    "print(\"Number of variants to investigate in the context of Tier3 analysis: {}\".format(df_pre_tier3_variants.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate variants according to mutation type\n",
    "# exonic / no synonymous / no splice variants region / checked they are all intronic atm\n",
    "exonic = df_pre_tier3_variants[df_pre_tier3_variants[\"csq_minimal\"].isin([\"Missense\", \"Inframe_Indel\"])]\n",
    "\n",
    "# missense\n",
    "missense_pre_tier3 = df_pre_tier3_variants[df_pre_tier3_variants[\"csq_minimal\"]==\"Missense\"]\n",
    "\n",
    "# inframe indel\n",
    "inframe_indels_tier3 = df_pre_tier3_variants[df_pre_tier3_variants[\"csq_minimal\"]==\"Inframe_Indel\"]\n",
    "\n",
    "# untranslated_region\n",
    "untranslated_regions_tier3 = df_pre_tier3_variants[df_pre_tier3_variants[\"csq_minimal\"].isin(['Intergene', 'UTR', 'Intron', 'Splice_region'])]\n",
    "\n",
    "# synonymous\n",
    "synonymous = df_pre_tier3_variants[df_pre_tier3_variants[\"csq_minimal\"]==\"Synonymous\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply filtration to whole pre_tier3 collection (considering all mutation type)\n",
    "- two filtration:\n",
    "    - deleteriouness \n",
    "    - spliceai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create filtration \n",
    "def filter_tier3(df):\n",
    "    df = df[((df['metalr_pred'] == \"D\") | (df['metalr_pred'].isnull())) &\n",
    "           ((df['m_cap_pred'] == \"D\") | (df['m_cap_pred'].isnull())) &\n",
    "           ((df['sift']==\"deleterious\") | (df['sift'].isnull())) &\n",
    "           ((df['polyphen'].isin([\"probably_damaging\", \"possibly_damaging\"]))  | (df['polyphen'].isnull())) &\n",
    "           ((df['mutationtaster_pred']=='D&D') | (df['mutationtaster_pred']=='D') | (df['mutationtaster_pred']=='A') | (df['mutationtaster_pred'].isnull())) &\n",
    "           ((df['cadd']>=(15)) | (df['cadd'].isnull())) & \n",
    "           ((df['dann']>=(0.98)) | (df['dann'].isnull())) &\n",
    "           ((df['revel']>=(0.5)) | (df['revel'].isnull())) &\n",
    "           ((df['provean_pred'].isin([\"D&D\", \"D\"])) | (df['provean_pred'].isnull()))]\n",
    "    return df\n",
    "\n",
    "def filter_spliceai(df, min_score=0.2):\n",
    "    df = df[\n",
    "            (df['spliceai_pred_DS_AG']>=min_score) |\n",
    "            (df['spliceai_pred_DS_AL']>=min_score) |\n",
    "            (df['spliceai_pred_DS_DG']>=min_score) |\n",
    "            (df['spliceai_pred_DS_DL']>=min_score) \n",
    "    ]\n",
    "    return df\n",
    "\n",
    "# main filtration\n",
    "df_filtered_pre_tier3 = filter_tier3(exonic)\n",
    "    \n",
    "# spliceai filtration\n",
    "df_splice_filtered_pre_tier3 = filter_spliceai(df_pre_tier3_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 58)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_pre_tier3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 58)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_splice_filtered_pre_tier3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge splice and filtered variants filtered\n",
    "df_filtered_tier3_stage1 = pd.concat([df_filtered_pre_tier3, df_splice_filtered_pre_tier3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dilution/.pyenv/versions/3.7.7/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# from filtered list fetch cases with variants\n",
    "filtered_variants_tiers3 = df_filtered_tier3_stage1[\"Variant_based_id\"].unique()\n",
    "# get cases id\n",
    "cases_filtered_tier3_stage1 = df_tier3_prep[df_tier3_prep[\"Variant_based_id\"].isin(filtered_variants_tiers3)][\"local_case_id\"].unique()\n",
    "# get df\n",
    "df_tier3_cases_stage1 = df_tier3_prep[df_tier3_prep[\"local_case_id\"].isin(cases_filtered_tier3_stage1)]\n",
    "\n",
    "# did variant pass filtration?\n",
    "def flag_variant_filter(x, pass_v_l):\n",
    "    if x in pass_v_l:\n",
    "        return \"y\"\n",
    "    else: \n",
    "        return \"n\"\n",
    "    \n",
    "df_tier3_cases_stage1[\"pass_tier3_filtration\"] = df_tier3_cases_stage1[\"Variant_based_id\"].apply(lambda x: flag_variant_filter(x, filtered_variants_tiers3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save variants passing filtration\n",
    "df_filtered_tier3_stage1.to_csv(\"SPG7/tier3/stage1_tier3_variants.tsv\", sep=\"\\t\", index=False)\n",
    "df_filtered_tier3_stage1.to_excel(\"SPG7/tier3/stage1_tier3_variants.xlsx\", index=False, freeze_panes=(1,4))\n",
    "\n",
    "# save cases carrying variant\n",
    "df_tier3_cases_stage1.to_csv(\"SPG7/tier3/stage1_tier3_cases.tsv\", sep=\"\\t\", index=False)\n",
    "df_tier3_cases_stage1.to_excel(\"SPG7/tier3/stage1_tier3_cases.xlsx\", index=False, freeze_panes=(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_tier3_cases_stage1[\"local_case_id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define hotspot regions\n",
    "\n",
    "- Located in a mutational hot spot and/or critical and well-established functional domain without benign variation. (Pathogenic, Moderate)\n",
    "    - based on clinical variants (benign/likely benign vs pathogenic/likely pathogenic)\n",
    "\n",
    "- exons ±5 bp (to include splice donor and acceptor):\n",
    "    - using 25bp on either side of the variant, the rule checks that there are at least 5 pathogenic variants (only using missense and inframe-indel variants).\n",
    "- protein domains:\n",
    "    - if the variant is within a functional domain\n",
    "    - checks that at least 2 pathogenic variants have been reported within the domain. \n",
    "    - trigger if the ratio of pathogenic to the total variants is greater than 0.2537 with strength 'supporting', and 0.2875 with strength 'moderate'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pool benign variants \n",
    "# combine clinvar uniprot benign reported\n",
    "uniprot_benign = uniprot_var[uniprot_var[\"clinsig\"]==1].reset_index(drop=True)[['Variant_based_id', 'chrom', 'pos', 'ref', 'alt', 'csq', 'gene',\n",
    "       'hgvsc', 'hgvsp', 'clinsig', 'hgvsp_clean', 'hgvsp_short',\n",
    "       'protein_pos', 'domain_name', 'cat_domain']]\n",
    "clinvar_benign = df_spg7_clinvar[df_spg7_clinvar[\"clinsig\"].isin(['Likely_benign', 'Benign', 'Benign/Likely_benign'])].reset_index(drop=True)[['Variant_based_id', 'chrom', 'pos', 'ref', 'alt', 'csq', 'gene',\n",
    "       'hgvsc', 'hgvsp', 'clinsig', 'hgvsp_clean', 'hgvsp_short',\n",
    "       'protein_pos', 'domain_name', 'cat_domain']]\n",
    "\n",
    "df_benign = pd.concat([uniprot_benign, clinvar_benign], sort=False)\n",
    "df_benign = df_benign.drop_duplicates(subset='Variant_based_id', keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pool lp/p variants \n",
    "# combine clinvar uniprot and flagged lp/p\n",
    "uniprot_lp_p = uniprot_var[uniprot_var[\"clinsig\"]==3].reset_index(drop=True)[['Variant_based_id', 'chrom', 'pos', 'ref', 'alt', 'csq', 'gene',\n",
    "       'hgvsc', 'hgvsp', 'hgvsp_clean', 'hgvsp_short',\n",
    "       'protein_pos', 'domain_name', 'cat_domain']]\n",
    "\n",
    "clinvar_lp_p = df_spg7_clinvar[df_spg7_clinvar[\"clinsig\"].isin(['Likely_pathogenic', 'Pathogenic/Likely_pathogenic', 'Pathogenic'])].reset_index(drop=True)[['Variant_based_id', 'chrom', 'pos', 'ref', 'alt', 'csq', 'gene',\n",
    "       'hgvsc', 'hgvsp', 'hgvsp_clean', 'hgvsp_short',\n",
    "       'protein_pos', 'domain_name', 'cat_domain']]\n",
    "\n",
    "\n",
    "lp_p_prospax = df_spg7_extended[df_spg7_extended[\"Variant_based_id\"].isin(final_lp_p_id)].reset_index(drop=True)[['Variant_based_id', 'chrom', 'pos', 'ref', 'alt', 'csq', 'gene',\n",
    "       'hgvsc', 'hgvsp', 'hgvsp_clean', 'hgvsp_short',\n",
    "       'protein_pos', 'domain_name', 'cat_domain']]\n",
    "\n",
    "\n",
    "df_lp_p = pd.concat([uniprot_lp_p, clinvar_lp_p, lp_p_prospax], sort=False)\n",
    "df_lp_p = df_lp_p.drop_duplicates(subset='Variant_based_id', keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_window(x):\n",
    "    up_x = x - 25\n",
    "    down_x = x + 25\n",
    "    window = (up_x, down_x)\n",
    "    return window\n",
    "\n",
    "def is_benign_in_window(window):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submitter_id</th>\n",
       "      <th>local_case_id</th>\n",
       "      <th>local_family_id</th>\n",
       "      <th>prospax_case_id</th>\n",
       "      <th>ngs_database_id</th>\n",
       "      <th>main_phenotype</th>\n",
       "      <th>case_status</th>\n",
       "      <th>id</th>\n",
       "      <th>gene</th>\n",
       "      <th>chrom</th>\n",
       "      <th>...</th>\n",
       "      <th>prot_change</th>\n",
       "      <th>genotype</th>\n",
       "      <th>compound_het_id_s</th>\n",
       "      <th>paxgene_availability</th>\n",
       "      <th>pbmc_availability</th>\n",
       "      <th>fibroblasts_availability</th>\n",
       "      <th>comments</th>\n",
       "      <th>Variant_based_id</th>\n",
       "      <th>tier1_is_solved</th>\n",
       "      <th>is_tier2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1 - Tübingen</td>\n",
       "      <td>ID11205</td>\n",
       "      <td>FN11205</td>\n",
       "      <td>843-594-125</td>\n",
       "      <td>TreatHSP Registry</td>\n",
       "      <td>HSP</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P1_SPG7_Tubingen_1</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>p.Ala510Val</td>\n",
       "      <td>Hom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-89613145-C-T</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P1 - Tübingen</td>\n",
       "      <td>ID11206</td>\n",
       "      <td>FN11205</td>\n",
       "      <td>409-682-435</td>\n",
       "      <td>TreatHSP Registry</td>\n",
       "      <td>HSP</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P1_SPG7_Tubingen_2</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>p.Ala510Val</td>\n",
       "      <td>Hom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-89613145-C-T</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P1 - Tübingen</td>\n",
       "      <td>ID12357</td>\n",
       "      <td>FN12357</td>\n",
       "      <td>855-065-005</td>\n",
       "      <td>TreatHSP Registry</td>\n",
       "      <td>HSP</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P1_SPG7_Tubingen_4</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Het</td>\n",
       "      <td>P1_SPG7_Tubingen_3</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-89613169-G-T</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P1 - Tübingen</td>\n",
       "      <td>ID14354</td>\n",
       "      <td>FN14354</td>\n",
       "      <td>892-430-990</td>\n",
       "      <td>TreatHSP Registry</td>\n",
       "      <td>HSP</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P1_SPG7_Tubingen_5</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>p.Trp29Ter</td>\n",
       "      <td>Hom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-89574911-G-A</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P1 - Tübingen</td>\n",
       "      <td>ID14645</td>\n",
       "      <td>FN14645</td>\n",
       "      <td>023-180-504</td>\n",
       "      <td>TreatHSP Registry</td>\n",
       "      <td>HSP</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P1_SPG7_Tubingen_8</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>p.Glu484GlyfsTer74</td>\n",
       "      <td>Hom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-89613169-G-T</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>P7 - Paris</td>\n",
       "      <td>AAR-SAL-DUR-282-003</td>\n",
       "      <td>AAR-SAL-DUR-282</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Paris diagnostic pipeline</td>\n",
       "      <td>ataxia</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P7_SPG7_Paris_167</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>p.Ala510Val</td>\n",
       "      <td>Het</td>\n",
       "      <td>P7_SPG7_Paris_168</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NONE</td>\n",
       "      <td>16-89613145-C-T</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>P7 - Paris</td>\n",
       "      <td>AAR-SAL-DUR-282-005</td>\n",
       "      <td>AAR-SAL-DUR-282</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Paris diagnostic pipeline</td>\n",
       "      <td>ataxia</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P7_SPG7_Paris_169</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>p.Ala510Val</td>\n",
       "      <td>Het</td>\n",
       "      <td>P7_SPG7_Paris_170</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NONE</td>\n",
       "      <td>16-89613145-C-T</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>P7 - Paris</td>\n",
       "      <td>FSP-SAL-COU-1416-001</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Paris diagnostic pipeline</td>\n",
       "      <td>HSP</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P7_SPG7_Paris_171</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>p.Pro350GlnfsTer36</td>\n",
       "      <td>Het</td>\n",
       "      <td>P7_SPG7_Paris_172</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NONE</td>\n",
       "      <td>16-89598372-CCCCCCGGCTGTGGGAAGACGCTGCTGGCC-C</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>P7 - Paris</td>\n",
       "      <td>FSP-SAL-SER-1476-001</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Paris diagnostic pipeline</td>\n",
       "      <td>HSP</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P7_SPG7_Paris_173</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>p.Arg485_Glu487del</td>\n",
       "      <td>Het</td>\n",
       "      <td>P7_SPG7_Paris_174</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NONE</td>\n",
       "      <td>16-89613069-AGGCGGGAGA-A</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>P7 - Paris</td>\n",
       "      <td>AAD-SAL-BOL-1260-001</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Paris diagnostic pipeline</td>\n",
       "      <td>ataxia</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P7_SPG7_Paris_175</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>p.Ala510Val</td>\n",
       "      <td>Hom</td>\n",
       "      <td>NONE</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NONE</td>\n",
       "      <td>16-89613145-C-T</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submitter_id         local_case_id  local_family_id prospax_case_id  \\\n",
       "0    P1 - Tübingen               ID11205          FN11205     843-594-125   \n",
       "1    P1 - Tübingen               ID11206          FN11205     409-682-435   \n",
       "2    P1 - Tübingen               ID12357          FN12357     855-065-005   \n",
       "4    P1 - Tübingen               ID14354          FN14354     892-430-990   \n",
       "5    P1 - Tübingen               ID14645          FN14645     023-180-504   \n",
       "..             ...                   ...              ...             ...   \n",
       "869     P7 - Paris   AAR-SAL-DUR-282-003  AAR-SAL-DUR-282            NONE   \n",
       "871     P7 - Paris   AAR-SAL-DUR-282-005  AAR-SAL-DUR-282            NONE   \n",
       "873     P7 - Paris  FSP-SAL-COU-1416-001             NONE            NONE   \n",
       "875     P7 - Paris  FSP-SAL-SER-1476-001             NONE            NONE   \n",
       "877     P7 - Paris  AAD-SAL-BOL-1260-001             NONE            NONE   \n",
       "\n",
       "               ngs_database_id main_phenotype  case_status  \\\n",
       "0            TreatHSP Registry            HSP  solved SPG7   \n",
       "1            TreatHSP Registry            HSP  solved SPG7   \n",
       "2            TreatHSP Registry            HSP  solved SPG7   \n",
       "4            TreatHSP Registry            HSP  solved SPG7   \n",
       "5            TreatHSP Registry            HSP  solved SPG7   \n",
       "..                         ...            ...          ...   \n",
       "869  Paris diagnostic pipeline         ataxia  solved SPG7   \n",
       "871  Paris diagnostic pipeline         ataxia  solved SPG7   \n",
       "873  Paris diagnostic pipeline            HSP  solved SPG7   \n",
       "875  Paris diagnostic pipeline            HSP  solved SPG7   \n",
       "877  Paris diagnostic pipeline         ataxia  solved SPG7   \n",
       "\n",
       "                     id  gene  chrom  ...         prot_change genotype  \\\n",
       "0    P1_SPG7_Tubingen_1  SPG7     16  ...         p.Ala510Val      Hom   \n",
       "1    P1_SPG7_Tubingen_2  SPG7     16  ...         p.Ala510Val      Hom   \n",
       "2    P1_SPG7_Tubingen_4  SPG7     16  ...                 NaN      Het   \n",
       "4    P1_SPG7_Tubingen_5  SPG7     16  ...          p.Trp29Ter      Hom   \n",
       "5    P1_SPG7_Tubingen_8  SPG7     16  ...  p.Glu484GlyfsTer74      Hom   \n",
       "..                  ...   ...    ...  ...                 ...      ...   \n",
       "869   P7_SPG7_Paris_167  SPG7     16  ...         p.Ala510Val      Het   \n",
       "871   P7_SPG7_Paris_169  SPG7     16  ...         p.Ala510Val      Het   \n",
       "873   P7_SPG7_Paris_171  SPG7     16  ...  p.Pro350GlnfsTer36      Het   \n",
       "875   P7_SPG7_Paris_173  SPG7     16  ...  p.Arg485_Glu487del      Het   \n",
       "877   P7_SPG7_Paris_175  SPG7     16  ...         p.Ala510Val      Hom   \n",
       "\n",
       "      compound_het_id_s paxgene_availability pbmc_availability  \\\n",
       "0                   NaN                   no                no   \n",
       "1                   NaN                   no                no   \n",
       "2    P1_SPG7_Tubingen_3                  yes               yes   \n",
       "4                   NaN                   no                no   \n",
       "5                   NaN                  yes                no   \n",
       "..                  ...                  ...               ...   \n",
       "869   P7_SPG7_Paris_168                   no               yes   \n",
       "871   P7_SPG7_Paris_170                   no               yes   \n",
       "873   P7_SPG7_Paris_172                   no               yes   \n",
       "875   P7_SPG7_Paris_174                   no               yes   \n",
       "877                NONE                   no               yes   \n",
       "\n",
       "    fibroblasts_availability comments  \\\n",
       "0                         no      NaN   \n",
       "1                         no      NaN   \n",
       "2                        yes      NaN   \n",
       "4                        yes      NaN   \n",
       "5                         no      NaN   \n",
       "..                       ...      ...   \n",
       "869                       no     NONE   \n",
       "871                       no     NONE   \n",
       "873                       no     NONE   \n",
       "875                       no     NONE   \n",
       "877                       no     NONE   \n",
       "\n",
       "                                 Variant_based_id tier1_is_solved is_tier2  \n",
       "0                                 16-89613145-C-T               y        n  \n",
       "1                                 16-89613145-C-T               y        n  \n",
       "2                                 16-89613169-G-T               y        n  \n",
       "4                                 16-89574911-G-A               y        n  \n",
       "5                                 16-89613169-G-T               y        n  \n",
       "..                                            ...             ...      ...  \n",
       "869                               16-89613145-C-T               y        n  \n",
       "871                               16-89613145-C-T               y        n  \n",
       "873  16-89598372-CCCCCCGGCTGTGGGAAGACGCTGCTGGCC-C               n        y  \n",
       "875                      16-89613069-AGGCGGGAGA-A               n        y  \n",
       "877                               16-89613145-C-T               y        n  \n",
       "\n",
       "[238 rows x 25 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "df_spg7[df_spg7[\"case_status\"]==\"solved SPG7\"].drop_duplicates(subset=[\"submitter_id\", \"local_case_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submitter_id</th>\n",
       "      <th>local_case_id</th>\n",
       "      <th>local_family_id</th>\n",
       "      <th>prospax_case_id</th>\n",
       "      <th>ngs_database_id</th>\n",
       "      <th>main_phenotype</th>\n",
       "      <th>case_status</th>\n",
       "      <th>id</th>\n",
       "      <th>gene</th>\n",
       "      <th>chrom</th>\n",
       "      <th>...</th>\n",
       "      <th>cdna</th>\n",
       "      <th>prot_change</th>\n",
       "      <th>genotype</th>\n",
       "      <th>compound_het_id_s</th>\n",
       "      <th>paxgene_availability</th>\n",
       "      <th>pbmc_availability</th>\n",
       "      <th>fibroblasts_availability</th>\n",
       "      <th>comments</th>\n",
       "      <th>Variant_based_id</th>\n",
       "      <th>tier1_is_solved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1 - Tübingen</td>\n",
       "      <td>ID11205</td>\n",
       "      <td>FN11205</td>\n",
       "      <td>843-594-125</td>\n",
       "      <td>TreatHSP Registry</td>\n",
       "      <td>HSP</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P1_SPG7_Tubingen_1</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>c.1529C&gt;T</td>\n",
       "      <td>p.Ala510Val</td>\n",
       "      <td>Hom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-89613145-C-T</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P1 - Tübingen</td>\n",
       "      <td>ID11206</td>\n",
       "      <td>FN11205</td>\n",
       "      <td>409-682-435</td>\n",
       "      <td>TreatHSP Registry</td>\n",
       "      <td>HSP</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P1_SPG7_Tubingen_2</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>c.1529C&gt;T</td>\n",
       "      <td>p.Ala510Val</td>\n",
       "      <td>Hom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-89613145-C-T</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P1 - Tübingen</td>\n",
       "      <td>ID12357</td>\n",
       "      <td>FN12357</td>\n",
       "      <td>855-065-005</td>\n",
       "      <td>TreatHSP Registry</td>\n",
       "      <td>HSP</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P1_SPG7_Tubingen_4</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>c.1552+1G&gt;T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Het</td>\n",
       "      <td>P1_SPG7_Tubingen_3</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-89613169-G-T</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P1 - Tübingen</td>\n",
       "      <td>ID14354</td>\n",
       "      <td>FN14354</td>\n",
       "      <td>892-430-990</td>\n",
       "      <td>TreatHSP Registry</td>\n",
       "      <td>HSP</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P1_SPG7_Tubingen_5</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>c.86G&gt;A</td>\n",
       "      <td>p.Trp29Ter</td>\n",
       "      <td>Hom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-89574911-G-A</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P1 - Tübingen</td>\n",
       "      <td>ID14645</td>\n",
       "      <td>FN14645</td>\n",
       "      <td>023-180-504</td>\n",
       "      <td>TreatHSP Registry</td>\n",
       "      <td>HSP</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P1_SPG7_Tubingen_8</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>c.1552+1G&gt;T</td>\n",
       "      <td>p.Glu484GlyfsTer74</td>\n",
       "      <td>Hom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-89613169-G-T</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>P7 - Paris</td>\n",
       "      <td>FSP-SAL-DEL-1469-001</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Paris diagnostic pipeline</td>\n",
       "      <td>HSP</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P7_SPG7_Paris_162</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>c.1529C&gt;T</td>\n",
       "      <td>p.Ala510Val</td>\n",
       "      <td>Het</td>\n",
       "      <td>P7_SPG7_Paris_163</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NONE</td>\n",
       "      <td>16-89613145-C-T</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>P7 - Paris</td>\n",
       "      <td>AAD-SAL-BON-1193-001</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Paris diagnostic pipeline</td>\n",
       "      <td>ataxia</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P7_SPG7_Paris_166</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>c.1529C&gt;T</td>\n",
       "      <td>p.Ala510Val</td>\n",
       "      <td>Hom</td>\n",
       "      <td>NONE</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NONE</td>\n",
       "      <td>16-89613145-C-T</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>P7 - Paris</td>\n",
       "      <td>AAR-SAL-DUR-282-003</td>\n",
       "      <td>AAR-SAL-DUR-282</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Paris diagnostic pipeline</td>\n",
       "      <td>ataxia</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P7_SPG7_Paris_167</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>c.1529C&gt;T</td>\n",
       "      <td>p.Ala510Val</td>\n",
       "      <td>Het</td>\n",
       "      <td>P7_SPG7_Paris_168</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NONE</td>\n",
       "      <td>16-89613145-C-T</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>P7 - Paris</td>\n",
       "      <td>AAR-SAL-DUR-282-005</td>\n",
       "      <td>AAR-SAL-DUR-282</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Paris diagnostic pipeline</td>\n",
       "      <td>ataxia</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P7_SPG7_Paris_169</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>c.1529C&gt;T</td>\n",
       "      <td>p.Ala510Val</td>\n",
       "      <td>Het</td>\n",
       "      <td>P7_SPG7_Paris_170</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NONE</td>\n",
       "      <td>16-89613145-C-T</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>P7 - Paris</td>\n",
       "      <td>AAD-SAL-BOL-1260-001</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Paris diagnostic pipeline</td>\n",
       "      <td>ataxia</td>\n",
       "      <td>solved SPG7</td>\n",
       "      <td>P7_SPG7_Paris_175</td>\n",
       "      <td>SPG7</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>c.1529C&gt;T</td>\n",
       "      <td>p.Ala510Val</td>\n",
       "      <td>Hom</td>\n",
       "      <td>NONE</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NONE</td>\n",
       "      <td>16-89613145-C-T</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      submitter_id         local_case_id  local_family_id prospax_case_id  \\\n",
       "0    P1 - Tübingen               ID11205          FN11205     843-594-125   \n",
       "1    P1 - Tübingen               ID11206          FN11205     409-682-435   \n",
       "2    P1 - Tübingen               ID12357          FN12357     855-065-005   \n",
       "4    P1 - Tübingen               ID14354          FN14354     892-430-990   \n",
       "5    P1 - Tübingen               ID14645          FN14645     023-180-504   \n",
       "..             ...                   ...              ...             ...   \n",
       "864     P7 - Paris  FSP-SAL-DEL-1469-001             NONE            NONE   \n",
       "868     P7 - Paris  AAD-SAL-BON-1193-001             NONE            NONE   \n",
       "869     P7 - Paris   AAR-SAL-DUR-282-003  AAR-SAL-DUR-282            NONE   \n",
       "871     P7 - Paris   AAR-SAL-DUR-282-005  AAR-SAL-DUR-282            NONE   \n",
       "877     P7 - Paris  AAD-SAL-BOL-1260-001             NONE            NONE   \n",
       "\n",
       "               ngs_database_id main_phenotype  case_status  \\\n",
       "0            TreatHSP Registry            HSP  solved SPG7   \n",
       "1            TreatHSP Registry            HSP  solved SPG7   \n",
       "2            TreatHSP Registry            HSP  solved SPG7   \n",
       "4            TreatHSP Registry            HSP  solved SPG7   \n",
       "5            TreatHSP Registry            HSP  solved SPG7   \n",
       "..                         ...            ...          ...   \n",
       "864  Paris diagnostic pipeline            HSP  solved SPG7   \n",
       "868  Paris diagnostic pipeline         ataxia  solved SPG7   \n",
       "869  Paris diagnostic pipeline         ataxia  solved SPG7   \n",
       "871  Paris diagnostic pipeline         ataxia  solved SPG7   \n",
       "877  Paris diagnostic pipeline         ataxia  solved SPG7   \n",
       "\n",
       "                     id  gene  chrom  ...         cdna         prot_change  \\\n",
       "0    P1_SPG7_Tubingen_1  SPG7     16  ...    c.1529C>T         p.Ala510Val   \n",
       "1    P1_SPG7_Tubingen_2  SPG7     16  ...    c.1529C>T         p.Ala510Val   \n",
       "2    P1_SPG7_Tubingen_4  SPG7     16  ...  c.1552+1G>T                 NaN   \n",
       "4    P1_SPG7_Tubingen_5  SPG7     16  ...      c.86G>A          p.Trp29Ter   \n",
       "5    P1_SPG7_Tubingen_8  SPG7     16  ...  c.1552+1G>T  p.Glu484GlyfsTer74   \n",
       "..                  ...   ...    ...  ...          ...                 ...   \n",
       "864   P7_SPG7_Paris_162  SPG7     16  ...    c.1529C>T         p.Ala510Val   \n",
       "868   P7_SPG7_Paris_166  SPG7     16  ...    c.1529C>T         p.Ala510Val   \n",
       "869   P7_SPG7_Paris_167  SPG7     16  ...    c.1529C>T         p.Ala510Val   \n",
       "871   P7_SPG7_Paris_169  SPG7     16  ...    c.1529C>T         p.Ala510Val   \n",
       "877   P7_SPG7_Paris_175  SPG7     16  ...    c.1529C>T         p.Ala510Val   \n",
       "\n",
       "    genotype   compound_het_id_s paxgene_availability pbmc_availability  \\\n",
       "0        Hom                 NaN                   no                no   \n",
       "1        Hom                 NaN                   no                no   \n",
       "2        Het  P1_SPG7_Tubingen_3                  yes               yes   \n",
       "4        Hom                 NaN                   no                no   \n",
       "5        Hom                 NaN                  yes                no   \n",
       "..       ...                 ...                  ...               ...   \n",
       "864      Het   P7_SPG7_Paris_163                   no               yes   \n",
       "868      Hom                NONE                   no               yes   \n",
       "869      Het   P7_SPG7_Paris_168                   no               yes   \n",
       "871      Het   P7_SPG7_Paris_170                   no               yes   \n",
       "877      Hom                NONE                   no               yes   \n",
       "\n",
       "    fibroblasts_availability comments Variant_based_id tier1_is_solved  \n",
       "0                         no      NaN  16-89613145-C-T               y  \n",
       "1                         no      NaN  16-89613145-C-T               y  \n",
       "2                        yes      NaN  16-89613169-G-T               y  \n",
       "4                        yes      NaN  16-89574911-G-A               y  \n",
       "5                         no      NaN  16-89613169-G-T               y  \n",
       "..                       ...      ...              ...             ...  \n",
       "864                       no     NONE  16-89613145-C-T               y  \n",
       "868                       no     NONE  16-89613145-C-T               y  \n",
       "869                       no     NONE  16-89613145-C-T               y  \n",
       "871                       no     NONE  16-89613145-C-T               y  \n",
       "877                       no     NONE  16-89613145-C-T               y  \n",
       "\n",
       "[195 rows x 24 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_solved[df_solved[\"case_status\"]==\"solved SPG7\"].drop_duplicates(subset=[\"submitter_id\", \"local_case_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397, 25)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spg7.drop_duplicates(subset=[\"submitter_id\", \"local_case_id\"]).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
